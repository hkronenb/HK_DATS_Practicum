{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from safegraph_py_functions import safegraph_py_functions as sgpy\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find .env automagically by walking up directories until it's found\n",
    "dotenv_path = find_dotenv()\n",
    "\n",
    "# load up the entries as environment variables\n",
    "load_dotenv(dotenv_path)\n",
    "root_dir = os.environ.get(\"ROOT_DIR\")\n",
    "raw_data_dir = os.path.join(root_dir,'data/raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# local directory where we want to put all the data\n",
    "patterns_path = os.path.join(raw_data_dir,'monthly-patterns')\n",
    "# print(local)\n",
    "files = []\n",
    "# r=root, d=directories, f = files\n",
    "for r, d, f in os.walk(patterns_path):\n",
    "    for file in f:\n",
    "        if 'normalization_stats.csv' in file:\n",
    "            files.append(os.path.join(patterns_path, r, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/hannahkronenberg/SafegraphCOVIDPhilly/data/raw/monthly-patterns/normalization_stats_backfill/2020/05/07/12/2019/03/normalization_stats.csv',\n",
       " '/Users/hannahkronenberg/SafegraphCOVIDPhilly/data/raw/monthly-patterns/normalization_stats_backfill/2020/05/07/12/2019/04/normalization_stats.csv',\n",
       " '/Users/hannahkronenberg/SafegraphCOVIDPhilly/data/raw/monthly-patterns/normalization_stats_backfill/2020/05/07/12/2019/05/normalization_stats.csv',\n",
       " '/Users/hannahkronenberg/SafegraphCOVIDPhilly/data/raw/monthly-patterns/normalization_stats_backfill/2020/05/07/12/2019/02/normalization_stats.csv',\n",
       " '/Users/hannahkronenberg/SafegraphCOVIDPhilly/data/raw/monthly-patterns/normalization_stats_backfill/2020/05/07/12/2019/11/normalization_stats.csv',\n",
       " '/Users/hannahkronenberg/SafegraphCOVIDPhilly/data/raw/monthly-patterns/normalization_stats_backfill/2020/05/07/12/2019/10/normalization_stats.csv',\n",
       " '/Users/hannahkronenberg/SafegraphCOVIDPhilly/data/raw/monthly-patterns/normalization_stats_backfill/2020/05/07/12/2019/07/normalization_stats.csv',\n",
       " '/Users/hannahkronenberg/SafegraphCOVIDPhilly/data/raw/monthly-patterns/normalization_stats_backfill/2020/05/07/12/2019/09/normalization_stats.csv',\n",
       " '/Users/hannahkronenberg/SafegraphCOVIDPhilly/data/raw/monthly-patterns/normalization_stats_backfill/2020/05/07/12/2019/08/normalization_stats.csv',\n",
       " '/Users/hannahkronenberg/SafegraphCOVIDPhilly/data/raw/monthly-patterns/normalization_stats_backfill/2020/05/07/12/2019/01/normalization_stats.csv',\n",
       " '/Users/hannahkronenberg/SafegraphCOVIDPhilly/data/raw/monthly-patterns/normalization_stats_backfill/2020/05/07/12/2019/06/normalization_stats.csv',\n",
       " '/Users/hannahkronenberg/SafegraphCOVIDPhilly/data/raw/monthly-patterns/normalization_stats_backfill/2020/05/07/12/2019/12/normalization_stats.csv',\n",
       " '/Users/hannahkronenberg/SafegraphCOVIDPhilly/data/raw/monthly-patterns/normalization_stats_backfill/2020/05/07/12/2020/03/normalization_stats.csv',\n",
       " '/Users/hannahkronenberg/SafegraphCOVIDPhilly/data/raw/monthly-patterns/normalization_stats_backfill/2020/05/07/12/2020/04/normalization_stats.csv',\n",
       " '/Users/hannahkronenberg/SafegraphCOVIDPhilly/data/raw/monthly-patterns/normalization_stats_backfill/2020/05/07/12/2020/02/normalization_stats.csv',\n",
       " '/Users/hannahkronenberg/SafegraphCOVIDPhilly/data/raw/monthly-patterns/normalization_stats_backfill/2020/05/07/12/2020/01/normalization_stats.csv',\n",
       " '/Users/hannahkronenberg/SafegraphCOVIDPhilly/data/raw/monthly-patterns/normalization_stats_backfill/2020/05/07/12/2018/03/normalization_stats.csv',\n",
       " '/Users/hannahkronenberg/SafegraphCOVIDPhilly/data/raw/monthly-patterns/normalization_stats_backfill/2020/05/07/12/2018/04/normalization_stats.csv',\n",
       " '/Users/hannahkronenberg/SafegraphCOVIDPhilly/data/raw/monthly-patterns/normalization_stats_backfill/2020/05/07/12/2018/05/normalization_stats.csv',\n",
       " '/Users/hannahkronenberg/SafegraphCOVIDPhilly/data/raw/monthly-patterns/normalization_stats_backfill/2020/05/07/12/2018/02/normalization_stats.csv',\n",
       " '/Users/hannahkronenberg/SafegraphCOVIDPhilly/data/raw/monthly-patterns/normalization_stats_backfill/2020/05/07/12/2018/11/normalization_stats.csv',\n",
       " '/Users/hannahkronenberg/SafegraphCOVIDPhilly/data/raw/monthly-patterns/normalization_stats_backfill/2020/05/07/12/2018/10/normalization_stats.csv',\n",
       " '/Users/hannahkronenberg/SafegraphCOVIDPhilly/data/raw/monthly-patterns/normalization_stats_backfill/2020/05/07/12/2018/07/normalization_stats.csv',\n",
       " '/Users/hannahkronenberg/SafegraphCOVIDPhilly/data/raw/monthly-patterns/normalization_stats_backfill/2020/05/07/12/2018/09/normalization_stats.csv',\n",
       " '/Users/hannahkronenberg/SafegraphCOVIDPhilly/data/raw/monthly-patterns/normalization_stats_backfill/2020/05/07/12/2018/08/normalization_stats.csv',\n",
       " '/Users/hannahkronenberg/SafegraphCOVIDPhilly/data/raw/monthly-patterns/normalization_stats_backfill/2020/05/07/12/2018/01/normalization_stats.csv',\n",
       " '/Users/hannahkronenberg/SafegraphCOVIDPhilly/data/raw/monthly-patterns/normalization_stats_backfill/2020/05/07/12/2018/06/normalization_stats.csv',\n",
       " '/Users/hannahkronenberg/SafegraphCOVIDPhilly/data/raw/monthly-patterns/normalization_stats_backfill/2020/05/07/12/2018/12/normalization_stats.csv',\n",
       " '/Users/hannahkronenberg/SafegraphCOVIDPhilly/data/raw/monthly-patterns/normalization_stats/2020/11/06/11/normalization_stats.csv',\n",
       " '/Users/hannahkronenberg/SafegraphCOVIDPhilly/data/raw/monthly-patterns/normalization_stats/2020/10/07/02/normalization_stats.csv',\n",
       " '/Users/hannahkronenberg/SafegraphCOVIDPhilly/data/raw/monthly-patterns/normalization_stats/2020/07/06/06/normalization_stats.csv',\n",
       " '/Users/hannahkronenberg/SafegraphCOVIDPhilly/data/raw/monthly-patterns/normalization_stats/2020/09/04/09/normalization_stats.csv',\n",
       " '/Users/hannahkronenberg/SafegraphCOVIDPhilly/data/raw/monthly-patterns/normalization_stats/2020/08/05/09/normalization_stats.csv',\n",
       " '/Users/hannahkronenberg/SafegraphCOVIDPhilly/data/raw/monthly-patterns/normalization_stats/2020/06/05/06/normalization_stats.csv']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for files with information disaggregated at the state level, keep only the country-wide info\n",
    "def keep_total_level(norm_stats):\n",
    "    if 'region' in norm_stats.columns:\n",
    "        if len(norm_stats[norm_stats['region'] == 'ALL_STATES']) == 0:\n",
    "            raise ValueError('no region named \"ALL_STATES\"')\n",
    "        norm_stats = norm_stats[norm_stats['region'] == 'ALL_STATES']\n",
    "        norm_stats = norm_stats.drop(columns = ['region'])\n",
    "    return norm_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_stats = pd.concat([keep_total_level(pd.read_csv(file)) for file in files], sort=True)\n",
    "norm_stats = norm_stats[norm_stats['year'] >= 2019]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_stats['year'] = norm_stats['year'].astype(int)\n",
    "norm_stats['month'] = norm_stats['month'].astype(int)\n",
    "norm_stats['day'] = norm_stats['day'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>total_devices_seen</th>\n",
       "      <th>total_home_visitors</th>\n",
       "      <th>total_home_visits</th>\n",
       "      <th>total_visits</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>19864233</td>\n",
       "      <td>15964091</td>\n",
       "      <td>27636202</td>\n",
       "      <td>69304245</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>19501615</td>\n",
       "      <td>15565360</td>\n",
       "      <td>26199538</td>\n",
       "      <td>62486898</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>19444962</td>\n",
       "      <td>16285916</td>\n",
       "      <td>27158187</td>\n",
       "      <td>55210974</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>19781861</td>\n",
       "      <td>16034434</td>\n",
       "      <td>27567027</td>\n",
       "      <td>63672615</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>19171193</td>\n",
       "      <td>15457780</td>\n",
       "      <td>26656320</td>\n",
       "      <td>63906175</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   day  month  total_devices_seen  total_home_visitors  total_home_visits  \\\n",
       "0    1      3            19864233             15964091           27636202   \n",
       "1    2      3            19501615             15565360           26199538   \n",
       "2    3      3            19444962             16285916           27158187   \n",
       "3    4      3            19781861             16034434           27567027   \n",
       "4    5      3            19171193             15457780           26656320   \n",
       "\n",
       "   total_visits  year  \n",
       "0      69304245  2019  \n",
       "1      62486898  2019  \n",
       "2      55210974  2019  \n",
       "3      63672615  2019  \n",
       "4      63906175  2019  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_stats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data_dir = os.path.join(root_dir,'data/processed')\n",
    "philly_patterns_df = pd.read_csv(os.path.join(processed_data_dir,'philly_patterns_by_zip.csv'))\n",
    "philly_patterns_df['postal_code'] = philly_patterns_df['postal_code'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "philly_patterns_df['date'] = pd.to_datetime(philly_patterns_df['date'], utc = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "philly_patterns_df['year'] = philly_patterns_df['date'].dt.year\n",
    "philly_patterns_df['month'] = philly_patterns_df['date'].dt.month\n",
    "philly_patterns_df['day'] = philly_patterns_df['date'].dt.day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "philly_patterns_df = philly_patterns_df.drop(columns = ['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "philly_patterns_df = philly_patterns_df.groupby(['year','month','day','postal_code']).agg('sum').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>day_visit_counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19102</td>\n",
       "      <td>4491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19103</td>\n",
       "      <td>3821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19104</td>\n",
       "      <td>5450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19106</td>\n",
       "      <td>2403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19107</td>\n",
       "      <td>7758</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  month  day postal_code  day_visit_counts\n",
       "0  2019      1    1       19102              4491\n",
       "1  2019      1    1       19103              3821\n",
       "2  2019      1    1       19104              5450\n",
       "3  2019      1    1       19106              2403\n",
       "4  2019      1    1       19107              7758"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "philly_patterns_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>num_zips</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [year, month, day, num_zips]\n",
       "Index: []"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check all dates have the same number of zips\n",
    "dates_df = philly_patterns_df.groupby(['year','month','day']).size().reset_index(name = 'num_zips')\n",
    "dates_df[dates_df['num_zips'] < max(dates_df.num_zips)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check patterns and stats have same number of days\n",
    "dfs = [philly_patterns_df, norm_stats]\n",
    "lens = [len(df.groupby(['year','month','day']).size()) for df in dfs]\n",
    "lens[0] == lens[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code below is no longer relevant. Was written for the original philly patterns data that had more variables\n",
    "#keep_cols = ['year','month','day', 'postal_code','day_visit_counts']\n",
    "#philly_patterns_df = philly_patterns_df[keep_cols].groupby(['year','month','day', 'postal_code']).agg('sum').reset_index()\n",
    "#philly_patterns_df['postal_code'] = philly_patterns_df['postal_code'].apply(lambda x: ('00000' + str(x))[-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# would be better to merge in every time we read a new month of data.\n",
    "philly_patterns_df = philly_patterns_df.merge(norm_stats, on = ['year','month','day'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "philly_patterns_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "philly_patterns_df['day_visits_normalized'] = philly_patterns_df['day_visit_counts']/philly_patterns_df['total_devices_seen']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_data = philly_patterns_df[['year','month','postal_code','day_visit_counts','day_visits_normalized']].groupby(['year','month','postal_code']).agg('sum').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(zip_data.postal_code.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_data = zip_data.merge(zip_data[zip_data['month'] == 1],  on = ['year','postal_code'], suffixes = (\"\",\"_jan\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_data['visits_relative'] = zip_data['day_visit_counts']/zip_data['day_visit_counts_jan']\n",
    "zip_data['visits_normalized_relative'] = zip_data['day_visits_normalized']/zip_data['day_visits_normalized_jan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_data = zip_data.drop(columns = [col for col in zip_data.columns if col.endswith('_jan')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_data = zip_data.rename(columns = {'day_visit_counts': 'visits', 'day_visits_normalized':'visits_normalized'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_data = zip_data[zip_data['year'] == 2020].merge(\n",
    "    zip_data[zip_data['year'] == 2019], \n",
    "    on = ['month','postal_code'], \n",
    "    suffixes = (\"_2020\",\"_2019\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = ['visits', 'visits_normalized', 'visits_relative', 'visits_normalized_relative']\n",
    "for metric in metrics:\n",
    "    plot_col = metric + '_dif'\n",
    "    zip_data[plot_col] = zip_data[metric+'_2020'] - zip_data[metric + '_2019']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_data = zip_data.drop(columns = ['year_2020','year_2019'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to directly download the zip3 shape file and format it.\n",
    "# Avoids putting the data into github.\n",
    "zip_shp = gpd.read_file(\"http://faculty.baruch.cuny.edu/geoportal/data/esri/usa/census/zip_poly.zip\")\n",
    "zip_shp.rename(columns={'ZIP':'postal_code'}, inplace=True)\n",
    "zip_shp = zip_shp[zip_shp['STATE'] == 'PA']\n",
    "zip_shp = zip_shp[['postal_code', 'geometry']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_shp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_shp['postal_code'].apply(len).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_data = zip_shp.merge(zip_data, on = ['postal_code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_data = zip_data.to_crs(epsg=3857)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = 'visits_normalized_relative'\n",
    "month = 4\n",
    "\n",
    "# Create the figure\n",
    "fig, ax = plt.subplots(facecolor=\"lightgray\", figsize=(8, 8))\n",
    "\n",
    "# NEW: Create a nice, lined up colorbar axes (called \"cax\" here)\n",
    "divider = make_axes_locatable(ax)\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.2)\n",
    "\n",
    "# Plot\n",
    "plot_df = zip_data[zip_data['month'] == month]\n",
    "col = metric + '_dif'\n",
    "plot_df.plot(ax=ax, cax=cax, column=col, edgecolor=\"none\", legend=True, cmap=\"viridis\")\n",
    "\n",
    "# NEW: Get the limits of the GeoDataFrame\n",
    "xmin, ymin, xmax, ymax = plot_df.total_bounds\n",
    "\n",
    "# NEW: Set the xlims and ylims\n",
    "ax.set_xlim(xmin, xmax)\n",
    "ax.set_ylim(ymin, ymax)\n",
    "\n",
    "# Format\n",
    "ax.set_axis_off()\n",
    "ax.set_aspect(\"equal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_data.postal_code.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
