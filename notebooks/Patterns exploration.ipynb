{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expedited patterns processing\n",
    "This notebook reads in the patterns data and:\n",
    "    1. Filters down to Philadelphia zipcodes based on a (currently hard-coded) list.\n",
    "        a. I have not yet run this using this list. Previously it filtered down by looking at the state and city columns in the data\n",
    "    3. Concatenates the files\n",
    "    4. Writes the result to philly_patterns.csv in the processed data folder.\n",
    "    \n",
    "It takes a long time to run and the resulting dataset is very large so it is worth thinking about ways to cut down the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from safegraph_py_functions import safegraph_py_functions as sgpy\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find .env automagically by walking up directories until it's found\n",
    "dotenv_path = find_dotenv()\n",
    "\n",
    "# load up the entries as environment variables\n",
    "load_dotenv(dotenv_path)\n",
    "root_dir = os.environ.get(\"ROOT_DIR\")\n",
    "raw_data_dir = os.path.join(root_dir,'data/raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# local directory where we want to put all the data\n",
    "patterns_path = os.path.join(raw_data_dir,'monthly-patterns')\n",
    "# print(local)\n",
    "files = []\n",
    "# r=root, d=directories, f = files\n",
    "for r, d, f in os.walk(patterns_path):\n",
    "    for file in f:\n",
    "        if file.endswith('.csv.gz') and 'patterns-part' in file:\n",
    "            files.append(os.path.join(patterns_path, r, file))\n",
    "#print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_cols = ['safegraph_place_id', 'location_name','street_address','city','region','postal_code',\n",
    "             'date_range_start', 'date_range_end', 'raw_visit_counts','raw_visitor_counts','visits_by_day',\n",
    "            'poi_cbg']\n",
    "\n",
    "def filter_to_philly(file):\n",
    "    # zip codes are read as integers rather than strings so we add leading zeros.\n",
    "    # this is not strictly necessary since Philadelphia zipcodes don't have leading zeros.\n",
    "    \n",
    "    # Philadelphia selection\n",
    "    # HK: adding leading zeros because some zipcodes in MA are 0191X.\n",
    "    df = pd.read_csv(file)\n",
    "    df['postal_code'] = df['postal_code'].apply(lambda x: ('00000'+str(x))[-5:])\n",
    "    in_philly = df['postal_code'].astype(str).str.startswith(\"191\")\n",
    "    df = df.loc[in_philly]\n",
    "    return df\n",
    "\n",
    "\n",
    "def filter_and_explode(file):\n",
    "    df = pd.read_csv(file)\n",
    "    df = df[keep_cols]\n",
    "    # zip codes are read as integers rather than strings so we add leading zeros.\n",
    "    # this is not strictly necessary since Philadelphia zipcodes don't have leading zeros.\n",
    "    df['postal_code'] = df['postal_code'].apply(lambda x: ('00000' + str(x))[-5:])\n",
    "    df = philly_zips.merge(df)\n",
    "    # The visits_by_day column contains a list of integers. \n",
    "    # This explodes that list so we get one row per day.\n",
    "    df = sgpy.explode_json_array(\n",
    "        df, array_column ='visits_by_day', value_col_name='day_visit_counts', \n",
    "        place_key='safegraph_place_id', file_key='date_range_start', array_sequence='day', \n",
    "        keep_index=False, zero_index=False)\n",
    "    df['date_range_start'] = pd.to_datetime(df['date_range_start'])\n",
    "    temp = df['day'].apply(lambda x: pd.Timedelta(x-1, unit='D'))\n",
    "    df['date'] = df['date_range_start'] + temp\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "philly_patterns = [filter_to_philly(file) for file in files]\n",
    "philly_patterns_df = pd.concat(philly_patterns)\n",
    "philly_patterns.to_csv(\n",
    "    os.path.join(processed_data_dir,'philly_patterns.csv'), index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data_dir = os.path.join(root_dir,'data/processed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "philly_patterns_df.to_csv(os.path.join(processed_data_dir,'philly_patterns.csv'), index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
