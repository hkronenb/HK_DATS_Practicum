{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expedited patterns processing\n",
    "This notebook reads in the patterns data and:\n",
    "    1. Filters down to Philadelphia zipcodes based on a (currently hard-coded) list.\n",
    "    2. Aggregates each file by zipcode\n",
    "    3. Concatenates the files\n",
    "    4. Writes the result to philly_patterns_by_zip.csv in the processed data folder.\n",
    "    \n",
    "It runs much faster than the original patterns exploration notebook which makes it useful \n",
    "for updating the zipcode map data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from safegraph_py_functions import safegraph_py_functions as sgpy\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find .env automagically by walking up directories until it's found\n",
    "dotenv_path = find_dotenv()\n",
    "\n",
    "# load up the entries as environment variables\n",
    "load_dotenv(dotenv_path)\n",
    "root_dir = os.environ.get(\"ROOT_DIR\")\n",
    "raw_data_dir = os.path.join(root_dir,'data/raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in all patterns files in the monthly-patterns folder\n",
    "\n",
    "patterns_path = os.path.join(raw_data_dir,'monthly-patterns')\n",
    "files = []\n",
    "# r=root, d=directories, f = files\n",
    "for r, d, f in os.walk(patterns_path):\n",
    "    for file in f:\n",
    "        if file.endswith('.csv.gz') and 'patterns-part' in file:\n",
    "            files.append(os.path.join(patterns_path, r, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This list was taken from https://www.city-data.com/zipmaps/Philadelphia-Pennsylvania.html\n",
    "philly_zips = pd.Series(['19102', '19103', '19104', '19106', '19107', '19109', '19111', '19112', '19114', '19115', \n",
    "               '19116', '19118', '19119', '19120', '19121', '19122', '19123', '19124', '19125', '19126', \n",
    "               '19127', '19128', '19129', '19130', '19131', '19132', '19133', '19134', '19135', '19136', \n",
    "               '19137', '19138', '19139', '19140', '19141', '19142', '19143', '19144', '19145', '19146', \n",
    "               '19147', '19148', '19149', '19150', '19151', '19152', '19153', '19154'], name = 'postal_code')\n",
    "\n",
    "philly_zips = philly_zips.to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in a csv with philly zipcodes\n",
    "# philly_zips = pd.read_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns that we keep and aggregate\n",
    "keep_cols = ['postal_code', 'safegraph_place_id', 'date_range_start', 'visits_by_day']\n",
    "# columns we keep after exploding\n",
    "keep_cols_2 = ['postal_code', 'date','day_visit_counts']\n",
    "# columns to group by\n",
    "group_by_cols = ['postal_code', 'date']\n",
    "\n",
    "def filter_and_explode(df):\n",
    "    df = df[keep_cols]\n",
    "    # zip codes are read as integers rather than strings so we add leading zeros.\n",
    "    # this is not strictly necessary since Philadelphia zipcodes don't have leading zeros.\n",
    "    df['postal_code'] = df['postal_code'].apply(lambda x: ('00000' + str(x))[-5:])\n",
    "    df = philly_zips.merge(df)\n",
    "    # The visits_by_day column contains a list of integers. \n",
    "    # This explodes that list so we get one row per day.\n",
    "    df = sgpy.explode_json_array(\n",
    "        df, array_column ='visits_by_day', value_col_name='day_visit_counts', \n",
    "        place_key='safegraph_place_id', file_key='date_range_start', array_sequence='day', \n",
    "        keep_index=False, zero_index=False)\n",
    "    df['date_range_start'] = pd.to_datetime(df['date_range_start'])\n",
    "    # Calculate the date for each row.\n",
    "    temp = df['day'].apply(lambda x: pd.Timedelta(x-1, unit='D'))\n",
    "    df['date'] = df['date_range_start'] + temp\n",
    "    df = df[keep_cols_2].groupby(group_by_cols).agg('sum').reset_index()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/envs/musa-620/lib/python3.6/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "philly_patterns = [filter_and_explode(pd.read_csv(file)) for file in files]\n",
    "philly_patterns_df = pd.concat(philly_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data_dir = os.path.join(root_dir,'data/processed')\n",
    "philly_patterns_df.to_csv(os.path.join(processed_data_dir,'philly_patterns_by_zip.csv'), index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
